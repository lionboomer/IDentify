{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Verbindung zu MongoDB herstellen\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "# Zugriff auf die Datenbank und Sammlung\n",
    "db = client[\"fingerprintDB\"]\n",
    "collection = db[\"fingerprints\"]\n",
    "\n",
    "# Daten für User 2 und User 3 abrufen\n",
    "user2_data = collection.find_one({\"username\": \"username_2\"})\n",
    "user3_data = collection.find_one({\"username\": \"username_3\"})\n",
    "\n",
    "# Daten für andere Benutzer abrufen (negative Beispiele)\n",
    "negative_data = collection.find({\"username\": {\"$nin\": [\"username_2\", \"username_3\"]}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import base64\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def decode_base64_image(base64_string):\n",
    "    base64_data = base64_string.split(\",\")[1]\n",
    "    byte_data = base64.b64decode(base64_data)\n",
    "    image_data = BytesIO(byte_data)\n",
    "    image = Image.open(image_data)\n",
    "    return np.array(image)\n",
    "\n",
    "def get_canvases(data):\n",
    "    return [decode_base64_image(canvas) for canvas in data[\"canvases\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canvases für User 2 und User 3\n",
    "user2_canvases = get_canvases(user2_data)\n",
    "user3_canvases = get_canvases(user3_data)\n",
    "\n",
    "# Positive Beispiele (User 2)\n",
    "X_positive = np.array(user2_canvases)\n",
    "y_positive = np.ones(len(X_positive))\n",
    "\n",
    "# Negative Beispiele (User 3)\n",
    "X_negative = np.array(user3_canvases)\n",
    "y_negative = np.zeros(len(X_negative))\n",
    "\n",
    "# Kombinieren der Daten\n",
    "X = np.concatenate((X_positive, X_negative), axis=0)\n",
    "y = np.concatenate((y_positive, y_negative), axis=0)\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binäre Klassifikation\n",
    "    return model\n",
    "\n",
    "input_shape = (35, 280, 4)  # Beispielhafte Eingabeform (Höhe, Breite, Kanäle)\n",
    "model = create_cnn_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95/95 [==============================] - 32s 320ms/step - loss: 12.7292 - accuracy: 0.7563 - val_loss: 0.0568 - val_accuracy: 0.9816\n",
      "Epoch 2/10\n",
      "95/95 [==============================] - 31s 324ms/step - loss: 0.0249 - accuracy: 0.9937 - val_loss: 0.0147 - val_accuracy: 0.9961\n",
      "Epoch 3/10\n",
      "95/95 [==============================] - 31s 322ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9974\n",
      "Epoch 4/10\n",
      "95/95 [==============================] - 29s 310ms/step - loss: 4.2151e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "95/95 [==============================] - 29s 311ms/step - loss: 1.2037e-04 - accuracy: 1.0000 - val_loss: 8.9742e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "95/95 [==============================] - 29s 307ms/step - loss: 8.1183e-05 - accuracy: 1.0000 - val_loss: 8.1011e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "95/95 [==============================] - 35s 364ms/step - loss: 5.8657e-05 - accuracy: 1.0000 - val_loss: 7.7397e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "95/95 [==============================] - 37s 387ms/step - loss: 4.5595e-05 - accuracy: 1.0000 - val_loss: 7.8060e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "95/95 [==============================] - 36s 378ms/step - loss: 3.4777e-05 - accuracy: 1.0000 - val_loss: 7.0506e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "95/95 [==============================] - 34s 358ms/step - loss: 2.7303e-05 - accuracy: 1.0000 - val_loss: 7.6144e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26a4071e0c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 82ms/step - loss: 7.6144e-04 - accuracy: 1.0000\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des Modells\n",
    "model.save('model/fingerprint_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created.\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "95/95 [==============================] - 17s 168ms/step - loss: 16.0010 - accuracy: 0.4918 - val_loss: 0.7032 - val_accuracy: 0.5171\n",
      "Epoch 2/10\n",
      "95/95 [==============================] - 15s 162ms/step - loss: 0.6794 - accuracy: 0.5697 - val_loss: 0.7252 - val_accuracy: 0.5118\n",
      "Epoch 3/10\n",
      "95/95 [==============================] - 15s 154ms/step - loss: 0.6472 - accuracy: 0.6191 - val_loss: 0.7240 - val_accuracy: 0.5158\n",
      "Epoch 4/10\n",
      "95/95 [==============================] - 15s 158ms/step - loss: 0.5977 - accuracy: 0.6770 - val_loss: 0.7886 - val_accuracy: 0.4882\n",
      "Epoch 5/10\n",
      "95/95 [==============================] - 15s 160ms/step - loss: 0.5427 - accuracy: 0.7240 - val_loss: 0.8070 - val_accuracy: 0.4895\n",
      "Epoch 6/10\n",
      "95/95 [==============================] - 15s 153ms/step - loss: 0.4834 - accuracy: 0.7572 - val_loss: 0.8702 - val_accuracy: 0.4934\n",
      "Epoch 7/10\n",
      "95/95 [==============================] - 16s 166ms/step - loss: 0.4059 - accuracy: 0.8151 - val_loss: 1.0160 - val_accuracy: 0.5013\n",
      "Epoch 8/10\n",
      "95/95 [==============================] - 15s 155ms/step - loss: 0.3145 - accuracy: 0.8678 - val_loss: 1.2296 - val_accuracy: 0.4618\n",
      "Epoch 9/10\n",
      "95/95 [==============================] - 15s 159ms/step - loss: 0.2282 - accuracy: 0.9072 - val_loss: 1.3739 - val_accuracy: 0.5053\n",
      "Epoch 10/10\n",
      "95/95 [==============================] - 14s 152ms/step - loss: 0.1642 - accuracy: 0.9395 - val_loss: 1.7003 - val_accuracy: 0.5039\n",
      "Model training completed.\n",
      "Saving the model...\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import base64\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Verbindung zu MongoDB herstellen\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"fingerprintDB\"]\n",
    "collection = db[\"fingerprints\"]\n",
    "\n",
    "# Daten für User 2 und User 3 abrufen\n",
    "user2_data = collection.find_one({\"username\": \"username_2\"})\n",
    "user3_data = collection.find_one({\"username\": \"username_3\"})\n",
    "\n",
    "# Funktion zum Dekodieren von Base64-Bildern\n",
    "def decode_base64_image(base64_string):\n",
    "    base64_data = base64_string.split(\",\")[1]\n",
    "    byte_data = base64.b64decode(base64_data)\n",
    "    image_data = BytesIO(byte_data)\n",
    "    image = Image.open(image_data)\n",
    "    return np.array(image)\n",
    "\n",
    "# Funktion zum Abrufen der Canvases\n",
    "def get_canvases(data):\n",
    "    return [decode_base64_image(canvas) for canvas in data[\"canvases\"]]\n",
    "\n",
    "# Canvases für User 2 und User 3\n",
    "user2_canvases = get_canvases(user2_data)\n",
    "user3_canvases = get_canvases(user3_data)\n",
    "\n",
    "# Positive Beispiele (User 2)\n",
    "X_positive = np.array(user2_canvases)\n",
    "y_positive = np.ones(len(X_positive))\n",
    "\n",
    "# Negative Beispiele (User 3)\n",
    "X_negative = np.array(user3_canvases)\n",
    "y_negative = np.zeros(len(X_negative))\n",
    "\n",
    "# Kombinieren der Daten\n",
    "X = np.concatenate((X_positive, X_negative), axis=0)\n",
    "y = np.concatenate((y_positive, y_negative), axis=0)\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Testsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# CNN-Modell erstellen\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binäre Klassifikation\n",
    "    return model\n",
    "\n",
    "try:\n",
    "    model.save('model/fingerprint_model.h5')\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while saving the model: {str(e)}\")\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "# Modell laden\n",
    "model = load_model('model/fingerprint_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def generate_random_canvas(txt):\n",
    "    # Erstelle ein neues Bild mit RGBA-Modus\n",
    "    canvas = Image.new('RGBA', (280, 35), (255, 255, 255, 0))\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "    \n",
    "    # Schriftart und Größe festlegen\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 18)\n",
    "    \n",
    "    # Text auf das Bild zeichnen\n",
    "    draw.text((2, 15), txt, font=font, fill=(0, 102, 204, 255))\n",
    "    draw.text((4, 19), txt, font=font, fill=(0, 102, 204, 179))\n",
    "    draw.text((2, 23), txt, font=font, fill=(0, 102, 204, 255))\n",
    "    draw.text((4, 27), txt, font=font, fill=(0, 102, 204, 179))\n",
    "    draw.text((2, 31), txt, font=font, fill=(0, 102, 204, 255))\n",
    "    draw.text((4, 35), txt, font=font, fill=(0, 102, 204, 179))\n",
    "    \n",
    "    # Bild in Base64 umwandeln\n",
    "    buffered = BytesIO()\n",
    "    canvas.save(buffered, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "# Beispiel-String\n",
    "example_string = \"example text\"\n",
    "canvas_image = generate_random_canvas(example_string)\n",
    "print(canvas_image)  # Dies gibt die Base64-Darstellung des Canvas zurück\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 267ms/step\n",
      "Prediction result: 0.4938583970069885\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "# Modell laden\n",
    "model = load_model('model/fingerprint_model.h5')\n",
    "\n",
    "# Funktion zum Dekodieren von Base64-Bildern\n",
    "def decode_base64_image(base64_string):\n",
    "    byte_data = base64.b64decode(base64_string)\n",
    "    image_data = BytesIO(byte_data)\n",
    "    image = Image.open(image_data)\n",
    "    return np.array(image)\n",
    "\n",
    "# Funktion zum Vorhersagen\n",
    "def predict_fingerprint(model, canvas_image):\n",
    "    # Bild dekodieren\n",
    "    image_array = decode_base64_image(canvas_image)\n",
    "    # Normalisieren der Bilddaten\n",
    "    image_array = image_array / 255.0\n",
    "    # Hinzufügen einer Batch-Dimension\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    # Vorhersage\n",
    "    prediction = model.predict(image_array)\n",
    "    return prediction[0][0]\n",
    "\n",
    "# Vorhersage durchführen\n",
    "prediction = predict_fingerprint(model, canvas_image)\n",
    "print(f\"Prediction result: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model for username_1\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 45s 396ms/step - loss: 8.3098 - accuracy: 0.8687 - val_loss: 0.0068 - val_accuracy: 0.9989\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 47s 428ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.0016 - val_accuracy: 0.9989\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 47s 423ms/step - loss: 1.0430e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9989\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 46s 419ms/step - loss: 3.2477e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9989\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 47s 424ms/step - loss: 1.9692e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9989\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 42s 382ms/step - loss: 1.3285e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9989\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 39s 356ms/step - loss: 9.2194e-06 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 39s 351ms/step - loss: 6.8933e-06 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "102/110 [==========================>...] - ETA: 2s - loss: 5.3442e-06 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import base64\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Verbindung zu MongoDB herstellen\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"fingerprintDB\"]\n",
    "collection = db[\"fingerprints\"]\n",
    "\n",
    "# Funktion zum Dekodieren von Base64-Bildern\n",
    "def decode_base64_image(base64_string):\n",
    "    base64_data = base64_string.split(\",\")[1]\n",
    "    byte_data = base64.b64decode(base64_data)\n",
    "    image_data = BytesIO(byte_data)\n",
    "    image = Image.open(image_data)\n",
    "    return np.array(image)\n",
    "\n",
    "# Funktion zum Abrufen der Canvases\n",
    "def get_canvases(data):\n",
    "    return [decode_base64_image(canvas) for canvas in data[\"canvases\"]]\n",
    "\n",
    "# CNN-Modell erstellen\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binäre Klassifikation\n",
    "    return model\n",
    "\n",
    "# Alle Benutzer abrufen\n",
    "users = list(collection.find({}))\n",
    "\n",
    "# Modelle für jeden Benutzer erstellen\n",
    "for user in users:\n",
    "    username = user['username']\n",
    "    print(f\"Creating model for {username}\")\n",
    "\n",
    "    # Positive Beispiele (Canvases des aktuellen Benutzers)\n",
    "    user_canvases = get_canvases(user)\n",
    "    X_positive = np.array(user_canvases)\n",
    "    y_positive = np.ones(len(X_positive))\n",
    "\n",
    "    # Negative Beispiele (Canvases der anderen Benutzer)\n",
    "    X_negative = []\n",
    "    y_negative = []\n",
    "\n",
    "    for other_user in users:\n",
    "        if other_user['username'] != username:\n",
    "            other_user_canvases = get_canvases(other_user)\n",
    "            X_negative.extend(other_user_canvases)\n",
    "            y_negative.extend([0] * len(other_user_canvases))\n",
    "\n",
    "    # Zufällig 2500 negative Beispiele auswählen\n",
    "    if len(X_negative) > 2500:\n",
    "        indices = np.random.choice(len(X_negative), 2500, replace=False)\n",
    "        X_negative = np.array(X_negative)[indices]\n",
    "        y_negative = np.array(y_negative)[indices]\n",
    "    else:\n",
    "        X_negative = np.array(X_negative)\n",
    "        y_negative = np.array(y_negative)\n",
    "\n",
    "    # Kombinieren der Daten\n",
    "    X = np.concatenate((X_positive, X_negative), axis=0)\n",
    "    y = np.concatenate((y_positive, y_negative), axis=0)\n",
    "\n",
    "    # Aufteilen der Daten in Trainings- und Testsets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Modell erstellen und trainieren\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model = create_cnn_model(input_shape)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Modell speichern\n",
    "    model_path = f'models/{username}_fingerprint_model.h5'\n",
    "    try:\n",
    "        model.save(model_path)\n",
    "        print(f\"Model for {username} saved successfully at {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the model for {username}: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
